{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yAIJhY1M41M",
    "tags": []
   },
   "source": [
    "# Data Challlenge: Help a Hematologist out!\n",
    "## Starter pack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo](https://github.com/christinab12/Data-challenge-logo/blob/main/logo.jpg?raw=true)\n",
    "\n",
    "## Getting started\n",
    "\n",
    "This notebook will get you started with downloading, exploring and analyzing the input and output data of the challenge, running a baseline model and creating a submission file to upload to the leaderboard.\n",
    "\n",
    "The challenge here is in transfer learning, precisely domain generalization (DG) and domain adaptation (DA) techniques. The focus lies on using deep neural networks to classify single white blood cell images obtained from peripheral blood smears. \n",
    "\n",
    "Three datasets, each constituting a different domain, will be used for this challenge:\n",
    "1. The Acevedo_20 dataset with labels\n",
    "2. The Matek_19 dataset with labels\n",
    "3. The WBC dataset without labels (Used for domain adaptation and performance measurement)\n",
    "\n",
    "The Acevedo_20 and Matek_19 datasets are labeled and should be used to train the model for the domain generalization task.\n",
    "A small subpart of the WBC dataset, WBC1, will be downloadable from the beginning of the challenge. It is unlabeled and should be used for evaluation and domain adaptation techniques.\n",
    "A second similar subpart of the WBC dataset, WBC2, will become available for download during phase 2 of the challenge, i.e. on the last day, 24 hours before submissions close.\n",
    "Tthe goal of this challenge is to achieve a high performance, especially a high f1 macro score, on the WBC2 dataset.\n",
    "\n",
    "This challenge wants to motivate research in domain generalization and adaptation techniques:\n",
    "\n",
    "To make actual use of deep learning in the medical routine, it is important that the techniques can be used in realistic cases. If a peripheral blood smear is acquired from a patient and classified by a neural network, it is important that this works reliably. But the patientâ€™s blood smear might very likely vary compared to the image domains used as training data of the network, resulting in not trustable results. To overcome this obstacle and build robust domain-invariant classifiers research in domain generalization and adaptation is needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bejqMsnM41a",
    "tags": []
   },
   "source": [
    "## Donwloading the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put this notebook in the folder you want to use for the setup of this challange and then download and unzip the data.\n",
    "\n",
    "**Note:** If you are using the **HAICORE** resources you will need to run this step in the login nodes, as the compute nodes do not have internet access. You might also consider running the next cell whihc unzips the downaloded files in the login node - it takes quite some time to unzip everything and will save you from wasting compute time ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --user YraZEdrHytaCSza --password BgZL3j8DT4 https://hmgubox2.helmholtz-muenchen.de/public.php/webdav/Acevedo_20.zip -O Acevedo_20.zip\n",
    "!wget --user YraZEdrHytaCSza --password BgZL3j8DT4 https://hmgubox2.helmholtz-muenchen.de/public.php/webdav/Matek_19.zip -O Matek_19.zip\n",
    "!wget --user YraZEdrHytaCSza --password BgZL3j8DT4 https://hmgubox2.helmholtz-muenchen.de/public.php/webdav/WBC1.zip -O WBC1.zip\n",
    "!wget --user YraZEdrHytaCSza --password BgZL3j8DT4 https://hmgubox2.helmholtz-muenchen.de/public.php/webdav/val_dummy.csv -O val_dummy.csv\n",
    "!wget --user YraZEdrHytaCSza --password BgZL3j8DT4 https://hmgubox2.helmholtz-muenchen.de/public.php/webdav/metadata2.csv -O metadata2.csv\n",
    "print('download complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Warning: This cell takes a long time to run!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.unpack_archive('Acevedo_20.zip', 'Datasets/Acevedo_20')\n",
    "shutil.unpack_archive('Matek_19.zip', 'Datasets/Matek_19')\n",
    "shutil.unpack_archive('WBC1.zip', 'Datasets/WBC1')\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For HAICORE users\n",
    "\n",
    "The first time you will instantiate the model it will need to be downloaded from the pytorch hub. So this cell also has to be run with an available internet connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "model = resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally you will need to install the imagecodes library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user imagecodecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Requirements\n",
    "This notebook uses sklearn and pytorch, but other deep learning libraries can also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import sleep\n",
    "from glob import glob\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import ntpath\n",
    "\n",
    "import numpy as np\n",
    "from imageio import imread\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, plot_confusion_matrix, matthews_corrcoef, classification_report,confusion_matrix, accuracy_score, balanced_accuracy_score, cohen_kappa_score, f1_score,  precision_score, recall_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# haicore users please uncomment the import below\n",
    "#import imagecodecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading the datasets please change the following paths to your local ones for the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = {\n",
    "        \"Ace_20\": \"Datasets/Acevedo_20\", # Acevedo_20 Dataset\n",
    "        \"Mat_19\": \"Datasets/Matek_19\", # Matek_19 Dataset\n",
    "        \"WBC1\": \"Datasets/WBC1\" # WBC1 dataset\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIeCjvyTM418",
    "tags": []
   },
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "In the following sections the selected datasets are going to be analyzed in some detail. All datasets consist of a collection of single cell images of peripheral blood smears.\n",
    "\n",
    "Between the three main datasets there are many differences. They were all acquired in different laboratories, using other stainings, scanners and magnifications and so forming separate data-domains. Also the sample size and the resolution differ. On top of this the labels or classes for each dataset are not entirely matching, so one has to come up with a smart way to map them. Another important aspect is the imbalance of samples per class. For example in the Matek_19 dataset the number of cells classified as basophil granulocytes is only 79, while in contrast the number of segmented neutrophil granulocytes is more than 8,000.\n",
    "\n",
    "The downloaded datasets where already relabeled into common classes, as subfolders, and some extremely underrepresented celltypes were left out. The remaining labels/subfolders are listed here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common classes of the datasets and their labels: \n",
    "# Highly underrepresented classes like atypical lymphocytes and smudge cells were left out.\n",
    "\n",
    "label_map_all = {\n",
    "        'basophil': 0,\n",
    "        'eosinophil': 1,\n",
    "        'erythroblast': 2,\n",
    "        'myeloblast' : 3,\n",
    "        'promyelocyte': 4,\n",
    "        'myelocyte': 5,\n",
    "        'metamyelocyte': 6,\n",
    "        'neutrophil_banded': 7,\n",
    "        'neutrophil_segmented': 8,\n",
    "        'monocyte': 9,\n",
    "        'lymphocyte_typical': 10\n",
    "    }\n",
    "\n",
    "label_map_reverse = {\n",
    "        0: 'basophil',\n",
    "        1: 'eosinophil',\n",
    "        2: 'erythroblast',\n",
    "        3: 'myeloblast',\n",
    "        4: 'promyelocyte',\n",
    "        5: 'myelocyte',\n",
    "        6: 'metamyelocyte',\n",
    "        7: 'neutrophil_banded',\n",
    "        8: 'neutrophil_segmented',\n",
    "        9: 'monocyte',\n",
    "        10: 'lymphocyte_typical'\n",
    "    }\n",
    "\n",
    "# The unlabeled WBC dataset gets the classname 'Data-Val' for every image\n",
    "\n",
    "label_map_pred = {\n",
    "        'DATA-VAL': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "We use pandas dataframes to systematically order and later load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath='metadata.csv' # path where the created dataframe will be stored\n",
    "\n",
    "def finding_classes(data_dir):\n",
    "    \"\"\"\n",
    "    this function finds the folders in the root path and considers them\n",
    "    as classes\n",
    "    \"\"\"\n",
    "    classes = [folder for folder in sorted(os.listdir(data_dir)) if not folder.startswith('.') and not folder.startswith('_')]\n",
    "    return classes\n",
    "\n",
    "\n",
    "def metadata_generator(data_path):\n",
    "    #this function generates a pandas dataframe containing image information (paths, labels, dataset)\n",
    "    metadata = pd.DataFrame(columns=[\"Image\", \"file\", \"label\", \"dataset\", \"set\"])\n",
    "    for ds in data_path:\n",
    "        list_of_classes = finding_classes(data_path[ds])\n",
    "        for cl in list_of_classes:\n",
    "            metadata_dummy = pd.DataFrame(columns=[\"Image\", \"file\", \"label\", \"dataset\", \"set\", 'mean1', 'mean2', 'mean3'])\n",
    "            metadata_dummy[\"Image\"] = None\n",
    "            metadata_dummy[\"file\"] = sorted(glob(os.path.join(data_path[ds], cl, \"*\")))\n",
    "            metadata_dummy[\"label\"] = cl\n",
    "            metadata_dummy[\"dataset\"] = ds\n",
    "            metadata_dummy[\"set\"] = \"train\"\n",
    "            for i in range(len(metadata_dummy)):\n",
    "                metadata_dummy['Image'].loc[i]=ntpath.basename(metadata_dummy['file'][i])\n",
    "            metadata = metadata.append(metadata_dummy, ignore_index=True)\n",
    "            metadata_dummy = None\n",
    "            \n",
    "    return metadata\n",
    "\n",
    "metadata = metadata_generator(data_path)\n",
    "\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fill in the rgb mean values, there are now two options:\n",
    "1. Load the downloadable dataframe 'metadata2.csv' with precomputed mean values (Here it is important that you didn't change the order of files in the dataset folders)\n",
    "2. Compute the mean values using the function listed below (takes about 10 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Option: Dataframe loading "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the following path to your downloaded metadata2.csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata2_path = \"metadata2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata2 = pd.read_csv(metadata2_path)\n",
    "print(metadata2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the order of images is the same for both dataframes (metadata and metadata2), add the rgb mean values to the metadata dataframe and save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data1=metadata.drop(columns=['file', 'label', 'dataset', 'set', 'mean1', 'mean2', 'mean3'])\n",
    "check_data2=metadata2.drop(columns=['mean1', 'mean2', 'mean3'])\n",
    "if check_data1.equals(check_data2):\n",
    "    metadata['mean1']=metadata2['mean1']\n",
    "    metadata['mean2']=metadata2['mean2']\n",
    "    metadata['mean3']=metadata2['mean3']\n",
    "    metadata.to_csv(savepath, index=False)\n",
    "    print('Worked! The rgb mean values were added')\n",
    "    print(f'The dataframe was saved to {savepath}')\n",
    "    print(metadata)\n",
    "else:\n",
    "    print('Files are not matching. Make sure you did not change the order or use option 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Option: Dataframe creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already computed the means of the datasets (download 'metadata2.csv', but if you want to compute them yourself the following script can be used:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be used to compute the mean of the datasets - *warning:* it takes some time to run this cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function computes the rgb mean values for all images in the the dataframe\n",
    "def compute_mean(dataframe=metadata, savepath=savepath, selected_channels=[0,1,2]):\n",
    "    for idx in tqdm(range(len(dataframe)), position=0, leave=True):\n",
    "        h5_file_path = dataframe.loc[idx,\"file\"]\n",
    "        try:\n",
    "            image= imread(h5_file_path)[:,:,selected_channels]\n",
    "        except ValueError: \n",
    "            print(h5_file_path)\n",
    "            break\n",
    "        #image = rgb2hsv(image)\n",
    "        dataframe.loc[idx, 'mean1']= np.mean(image[:,:,0])\n",
    "        dataframe.loc[idx, 'mean2']= np.mean(image[:,:,1])\n",
    "        dataframe.loc[idx, 'mean3']= np.mean(image[:,:,2])\n",
    "    dataframe.to_csv(savepath, index=False)\n",
    "    print(f'The dataframe was saved to {savepath}')\n",
    "    print(dataframe)\n",
    "    return dataframe\n",
    "\n",
    "compute_mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now the dataframe can be loaded using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(savepath)\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the different datasets will be viewed and discussed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ace_metadata=metadata.loc[metadata['dataset']=='Ace_20'].reset_index(drop = True)\n",
    "mat_metadata=metadata.loc[metadata['dataset']=='Mat_19'].reset_index(drop = True)\n",
    "wbc_metadata=metadata.loc[metadata['dataset']=='WBC1'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function shows a random sample of the dataset\n",
    "def data_sample(dataframe=metadata):\n",
    "    \n",
    "    n=random.randint(0, len(dataframe)-1)\n",
    "    image = mpimg.imread(dataframe.file[n])\n",
    "    plt.title(f'label: {dataframe.label[n]}')\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function shows information about the datasets classes and rgb means\n",
    "def data_report(dataframe=metadata, label=None, color1='lightblue', color2='darkblue'):\n",
    "\n",
    "    print('\\033[1m' + 'label \\t \\t \\timages'+ '\\033[0m')\n",
    "    print('')\n",
    "    print(f'total \\t \\t \\t{len(dataframe)}')\n",
    "    print(dataframe.label.value_counts())\n",
    " \n",
    "    x1=np.array(dataframe['mean1'])\n",
    "    x2=np.array(dataframe['mean2'])\n",
    "    x3=np.array(dataframe['mean3'])\n",
    "    mean1=np.mean(np.array(dataframe['mean1']))\n",
    "    mean2=np.mean(np.array(dataframe['mean2']))\n",
    "    mean3=np.mean(np.array(dataframe['mean3']))\n",
    "    std1=np.std(np.array(dataframe['mean1']))\n",
    "    std2=np.std(np.array(dataframe['mean2']))\n",
    "    std3=np.std(np.array(dataframe['mean3']))\n",
    "    print('\\033[1m' + 'mean \\t \\tstd'+ '\\033[0m')\n",
    "    print(f'red: {np.round_(mean1, decimals=2)} \\tred: {np.round_(std1, decimals=2)}')\n",
    "    print(f'green: {np.round_(mean2, decimals=2)} \\tgreen: {np.round_(std2, decimals=2)}')\n",
    "    print(f'blue: {np.round_(mean3, decimals=2)} \\tblue: {np.round_(std3, decimals=2)}')\n",
    "    print('')\n",
    "\n",
    "\n",
    "#this function plots the data\n",
    "def data_plot(dataframes=[ace_metadata, mat_metadata, wbc_metadata],\n",
    "                labels=['Ace_20', 'Mat_19', 'WBC1'],\n",
    "                colors1=['lightblue', 'orange', 'greenyellow'],\n",
    "                colors2=['darkblue', 'red', 'limegreen'],\n",
    "                save_name='plot_all'):\n",
    "\n",
    "    f, axarr = plt.subplots(1,3, figsize=(15,5))\n",
    "    df=0\n",
    "    while df<len(dataframes):\n",
    "        \n",
    "        dataframe = dataframes[df]\n",
    "        label=labels[df]\n",
    "        color1=colors1[df]\n",
    "        color2=colors2[df]\n",
    "\n",
    "        x1=np.array(dataframe['mean1'])\n",
    "        x2=np.array(dataframe['mean2'])\n",
    "        x3=np.array(dataframe['mean3'])\n",
    "        mean1=np.mean(np.array(dataframe['mean1']))\n",
    "        mean2=np.mean(np.array(dataframe['mean2']))\n",
    "        mean3=np.mean(np.array(dataframe['mean3']))\n",
    "        std1=np.std(np.array(dataframe['mean1']))\n",
    "        std2=np.std(np.array(dataframe['mean2']))\n",
    "        std3=np.std(np.array(dataframe['mean3']))\n",
    "        \n",
    "        # red vs green\n",
    "        \n",
    "        axarr[0].set_xlabel(\"red\")\n",
    "        axarr[0].set_ylabel(\"green\")\n",
    "\n",
    "        a=np.array((x1,x2)).T\n",
    "\n",
    "        axarr[0].scatter(a[:, 0], a[:, 1], s=3, color=color1, alpha=1)\n",
    "        axarr[0].scatter(x=mean1, y=mean2, s=1, color=color2)\n",
    "        axarr[0].plot([mean1-std1, mean1+std1],[mean2, mean2], color=color2, label=label)\n",
    "        axarr[0].plot([mean1, mean1],[mean2-std2, mean2+std2], color=color2)\n",
    "\n",
    "\n",
    "        # red vs blue\n",
    "\n",
    "        axarr[1].set_xlabel(\"red\")\n",
    "        axarr[1].set_ylabel(\"blue\")\n",
    "\n",
    "        b=np.array((x1,x3)).T\n",
    "\n",
    "        axarr[1].scatter(b[:, 0], b[:, 1], s=3, color=color1, alpha=1)\n",
    "        axarr[1].scatter(x=mean1, y=mean3, s=1, color=color2)\n",
    "        axarr[1].plot([mean1-std1, mean1+std1],[mean3, mean3], color=color2, label=label)\n",
    "        axarr[1].plot([mean1, mean1],[mean3-std3, mean3+std3], color=color2)\n",
    "\n",
    "\n",
    "        # green vs blue\n",
    "\n",
    "        axarr[2].set_xlabel(\"green\")\n",
    "        axarr[2].set_ylabel(\"blue\")\n",
    "\n",
    "        b=np.array((x2,x3)).T\n",
    "\n",
    "        axarr[2].scatter(b[:, 0], b[:, 1], s=3, color=color1, alpha=1)\n",
    "        axarr[2].scatter(x=mean1, y=mean3, s=1, color=color2)\n",
    "        axarr[2].plot([mean2-std2, mean2+std2],[mean3, mean3], color=color2, label=label)\n",
    "        axarr[2].plot([mean2, mean2],[mean3-std3, mean3+std3], color=color2)\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "        f.tight_layout()\n",
    "\n",
    "        df+=1\n",
    "        \n",
    "    plt.savefig(save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acevedo_20:\n",
    "- size: 360x363 pixels, 36.0 x 36.3 micrometers\n",
    "- 10 classes\n",
    "\n",
    "This dataset is a processed version of the original Acevedo_2020, containing 14291 images subdivided into 10 classes. The image size is 360 x 363 pixels and approximately 36.0 x 36.3 micrometers. Notice that this dataset only contains 10 classes, as it misses the myeloblast cells, which are found in the Mat_19 and WBC datasets.\n",
    "\n",
    "More information about the original dataset can be found online under:\n",
    "(https://www.sciencedirect.com/science/article/pii/S2352340920303681?via%3Dihub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list_pbc = [\n",
    "        'basophil',\n",
    "        'eosinophil',\n",
    "        'erythroblast',\n",
    "        'promyelocyte',\n",
    "        'myelocyte',\n",
    "        'metamyelocyte',\n",
    "        'neutrophil_banded',\n",
    "        'neutrophil_segmented',\n",
    "        'monocyte',\n",
    "        'lymphocyte_typical',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_report(ace_metadata)\n",
    "ace_plot=data_plot([ace_metadata], labels=['Ace_20'], save_name='plot_ace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ace_image=data_sample(ace_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Matek_19:\n",
    "- size: 400x400 pixels, 29.0 x 29.0 micrometers\n",
    "- 11 classes\n",
    "\n",
    "This dataset is a processed version of the one used by Matek et al. (Matek, 2019) for CNN training and will therefore be further referenced as Mat_19. It consists of 18321 samples, categorized into 11 classes, including the labels basophil, eosinophil and erythroblasts, further typical lymphocytes, monoblasts and monocytes, banded and segmented neutrophils and also several stages of immature granulocytes: myeloblasts, promyelocytes, myelocytes and metamyelocytes. Further each sample has a size of 400 x 400 pixels, corresponding to 29 x 29 micrometers.\n",
    "\n",
    "More information about the original dataset can be found online under:\n",
    "(https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=61080958)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list_all = [\n",
    "        'basophil',\n",
    "        'eosinophil',\n",
    "        'erythroblast',\n",
    "        'myeloblast',\n",
    "        'promyelocyte',\n",
    "        'myelocyte',\n",
    "        'metamyelocyte',\n",
    "        'neutrophil_banded',\n",
    "        'neutrophil_segmented',\n",
    "        'monocyte',\n",
    "        'lymphocyte_typical'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_report(mat_metadata)\n",
    "mat_plot=data_plot([mat_metadata], labels=['Mat_19'], save_name='plot_mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_image=data_sample(mat_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# WBC:\n",
    "- size: 288x288 pixels, 25.0 x 25.0 micrometers\n",
    "- 11 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_report(wbc_metadata)\n",
    "wbc_plot=data_plot([wbc_metadata], labels=['WBC'], save_name='plot_wbc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbc_image=data_sample(wbc_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of datasets and preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_report()\n",
    "all_plot1=data_plot([metadata], labels=['All'], save_name='plot_all1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plot2=data_plot(save_name='plot_all2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images center-cropped to 25x25 micrometers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_Ace20=250\n",
    "crop_Mat19=345\n",
    "crop_WBC1=288\n",
    "\n",
    "dataset_image_size = {\n",
    "    \"Ace_20\":crop_Ace20,   #250,\n",
    "    \"Mat_19\":crop_Mat19,   #345, \n",
    "    \"WBC1\":crop_WBC1,   #288,  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(image, crop_size):\n",
    "    h1 = (image.shape[0] - crop_size) /2\n",
    "    h1 = int(h1)\n",
    "    h2 = (image.shape[0] + crop_size) /2\n",
    "    h2 = int(h2)\n",
    "\n",
    "    w1 = (image.shape[1] - crop_size) /2\n",
    "    w1 = int(w1)\n",
    "    w2 = (image.shape[1] + crop_size) /2\n",
    "    w2 = int(w2)\n",
    "    cropped_image = image[h1:h2,w1:w2, :]\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(2,3, figsize=(10,10))\n",
    "\n",
    "axarr[0,0].set_title('Acevedo_20')\n",
    "axarr[0,0].imshow(ace_image)\n",
    "axarr[0,1].set_title('Matek_19')\n",
    "axarr[0,1].imshow(mat_image)\n",
    "axarr[0,2].set_title('WBC1')\n",
    "axarr[0,2].imshow(wbc_image)\n",
    "\n",
    "\n",
    "axarr[1,0].set_title('crop Acevedo_20')\n",
    "axarr[1,0].imshow(crop(ace_image, crop_Ace20))\n",
    "axarr[1,1].set_title('crop Matek_19')\n",
    "axarr[1,1].imshow(crop(mat_image, crop_Mat19))\n",
    "axarr[1,2].set_title('crop wbc1')\n",
    "axarr[1,2].imshow(crop(wbc_image, crop_WBC1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We advice to use the cropped images as this keeps the ratio of the area of the cell compared to background similar for all datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffcOqQaepyRE"
   },
   "source": [
    "# Dummy Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here a dummy CSV submission example is generated. No training is involved, but classes are randomly generated for the images. \n",
    "(here we use a constant classifier model for instance (sklearn's DummyClassifier for instance).)\n",
    "It's the simplest example for the participants to start with. \n",
    "\n",
    "Our WBC1 dataframe now looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wbc_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For submission we want to bring it into a different form, so it only shows:\n",
    "- filenames\n",
    "- the predicted labelnames\n",
    "- and their IDs\n",
    "\n",
    "This could be done by using random numbers for the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdata=wbc_metadata.drop(columns=['file','label', 'dataset', 'set', 'mean1', 'mean2', 'mean3'])\n",
    "outputdata['Label']=None\n",
    "outputdata['LabelID']=None\n",
    "for i in range(len(outputdata)):\n",
    "    outputdata['LabelID'].loc[i]=random.randint(0, 10) #for the 10 possible classes\n",
    "    outputdata['Label'].loc[i]=label_map_reverse[outputdata['LabelID'].loc[i]]\n",
    "outputdata.to_csv('submission.csv', index=False)\n",
    "print(outputdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now upload it to the leaderboard of the challenge website and see what performace you get for random!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Baseline simple solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data loading\n",
    "Load the data: Now the Acevedo_20 and Matek_19 datasets will be loaded and used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_metadata=metadata\n",
    "source_domains=['Ace_20', 'Mat_19']\n",
    "source_index = example_metadata.dataset.isin(source_domains)\n",
    "example_metadata = example_metadata.loc[source_index,:].copy().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\033[1m' + 'label \\t \\t \\timages'+ '\\033[0m')\n",
    "print('')\n",
    "print(f'total \\t \\t \\t{len(example_metadata)}')\n",
    "print(example_metadata.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the dataset will be divided into train-, validation- and a testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fraction=0.2 #of the whole dataset\n",
    "val_fraction=0.125 #of 0.8 of the dataset (corresponds to 0.1 of the whole set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index, test_index, train_label, test_label = train_test_split(\n",
    "    example_metadata.index,\n",
    "    example_metadata.label + \"_\" + example_metadata.dataset,\n",
    "    test_size=test_fraction,\n",
    "    random_state=0, \n",
    "    shuffle=True,\n",
    "    stratify=example_metadata.label\n",
    "    )\n",
    "example_metadata.loc[test_index, 'set']='test'\n",
    "train_val_metadata=example_metadata.loc[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index, val_index, train_label, val_label = train_test_split(\n",
    "    train_val_metadata.index,\n",
    "    train_val_metadata.label + \"_\" + train_val_metadata.dataset,\n",
    "    test_size=val_fraction,\n",
    "    random_state=0, \n",
    "    shuffle=True, \n",
    "    stratify=train_val_metadata.label\n",
    "    )\n",
    "example_metadata.loc[val_index, 'set']='val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See this for a summary of our dataset-fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=len(example_metadata.loc[example_metadata['set'] == 'train'])\n",
    "val_size=len(example_metadata.loc[example_metadata['set'] == 'val'])\n",
    "test_size=len(example_metadata.loc[example_metadata['set'] == 'test'])\n",
    "\n",
    "print('\\033[1m' + 'complete dataset'+ '\\033[0m')\n",
    "print('\\033[1m' + 'label \\t \\t \\timages'+ '\\033[0m')\n",
    "print('')\n",
    "print(f'total \\t \\t \\t{len(example_metadata)}')\n",
    "print(example_metadata.label.value_counts())\n",
    "print('')\n",
    "print('\\033[1m' + 'trainset'+ '\\033[0m')\n",
    "print('\\033[1m' + 'label \\t \\t \\timages'+ '\\033[0m')\n",
    "print('')\n",
    "print(f'total \\t \\t \\t{train_size}')\n",
    "print(example_metadata.loc[example_metadata['set'] == 'train'].label.value_counts())\n",
    "print('')\n",
    "print('\\033[1m' + 'validationset'+ '\\033[0m')\n",
    "print('\\033[1m' + 'label \\t \\t \\timages'+ '\\033[0m')\n",
    "print('')\n",
    "print(f'total \\t \\t \\t{val_size}')\n",
    "print(example_metadata.loc[example_metadata['set'] == 'val'].label.value_counts())\n",
    "print('')\n",
    "print('\\033[1m' + 'testset'+ '\\033[0m')\n",
    "print('\\033[1m' + 'label \\t \\t \\timages'+ '\\033[0m')\n",
    "print('')\n",
    "print(f'total \\t \\t \\t{test_size}')\n",
    "print(example_metadata.loc[example_metadata['set'] == 'test'].label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataset can be loaded. To enable cropping we present a costum DatasetGenerator class, that loads the images from the paths listed in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator(Dataset):\n",
    "\n",
    "    def __init__(self, \n",
    "                metadata, \n",
    "                reshape_size=64, \n",
    "                label_map=[],\n",
    "                dataset = [],\n",
    "                transform=None,\n",
    "                selected_channels = [0,1,2],\n",
    "                dataset_image_size=None):\n",
    "\n",
    "        self.metadata = metadata.copy().reset_index(drop = True)\n",
    "        self.label_map = label_map\n",
    "        self.transform = transform\n",
    "        self.selected_channels = selected_channels\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        ## get image and label\n",
    "        dataset =  self.metadata.loc[idx,\"dataset\"]\n",
    "        crop_size = dataset_image_size[dataset]\n",
    "        \n",
    "        h5_file_path = self.metadata.loc[idx,\"file\"]\n",
    "        image= imread(h5_file_path)[:,:,self.selected_channels]\n",
    "        image = image / 255.\n",
    "        h1 = (image.shape[0] - crop_size) /2\n",
    "        h1 = int(h1)\n",
    "        h2 = (image.shape[0] + crop_size) /2\n",
    "        h2 = int(h2)\n",
    "        \n",
    "        w1 = (image.shape[1] - crop_size) /2\n",
    "        w1 = int(w1)\n",
    "        w2 = (image.shape[1] + crop_size) /2\n",
    "        w2 = int(w2)\n",
    "        image = image[h1:h2,w1:w2, :]\n",
    "        image = np.transpose(image, (2, 0, 1))\n",
    "        label = self.metadata.loc[idx,\"label\"]\n",
    " \n",
    "\n",
    "        # map numpy array to tensor\n",
    "        image = torch.from_numpy(copy.deepcopy(image)) \n",
    "        image = image.float()\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image) \n",
    "        \n",
    "        label = self.label_map[label]\n",
    "        label = torch.tensor(label).long()\n",
    "        return image.float(),  label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want transformations. These you can easily change to your needs below.\n",
    "\n",
    "- resizing of the images to 224 x 224 pixels\n",
    "- random crop\n",
    "- number workers: 3\n",
    "- mean and standartdeviations used for datanormalization\n",
    "- batchsize: 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize=224 #image pixel size\n",
    "number_workers=3\n",
    "\n",
    "random_crop_scale=(0.8, 1.0)\n",
    "random_crop_ratio=(0.8, 1.2)\n",
    "\n",
    "mean=[0.485, 0.456, 0.406] #values from imagenet\n",
    "std=[0.229, 0.224, 0.225] #values from imagenet\n",
    "\n",
    "bs=32 #batchsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a train set, validation set and test set will be loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization = torchvision.transforms.Normalize(mean,std)\n",
    "\n",
    "train_transform = transforms.Compose([ \n",
    "        normalization,\n",
    "        transforms.RandomResizedCrop(resize, scale=random_crop_scale, ratio=random_crop_ratio),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip()\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([ \n",
    "        normalization,\n",
    "        transforms.Resize(resize)])\n",
    "\n",
    "test_transform = transforms.Compose([ \n",
    "        normalization,\n",
    "        transforms.Resize(resize)])\n",
    "\n",
    "#dataset-creation\n",
    "\n",
    "train_dataset = DatasetGenerator(example_metadata.loc[train_index,:], \n",
    "                                 reshape_size=resize, \n",
    "                                 dataset = source_domains,\n",
    "                                 label_map=label_map_all, \n",
    "                                 transform = train_transform,\n",
    "                                 )\n",
    "val_dataset = DatasetGenerator(example_metadata.loc[val_index,:], \n",
    "                                 reshape_size=resize, \n",
    "                                 dataset = source_domains,\n",
    "                                 label_map=label_map_all, \n",
    "                                 transform = val_transform,\n",
    "                                 )\n",
    "\n",
    "test_dataset = DatasetGenerator(example_metadata.loc[test_index,:], \n",
    "                                 reshape_size=resize, \n",
    "                                 dataset = source_domains,\n",
    "                                 label_map=label_map_all, \n",
    "                                 transform = test_transform,\n",
    "                                 )\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=bs, shuffle=True, num_workers=number_workers)\n",
    "valid_loader = DataLoader(\n",
    "    val_dataset, batch_size=bs, shuffle=True, num_workers=number_workers)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=bs, shuffle=False, num_workers=number_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for a last check, this function shows random samples of the dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation='nearest')\n",
    "    \n",
    "show((next(iter(train_loader))[0])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity and fast training we use a resnet18. We advise participants to stick with this model and not spend time on trying different architectures, but rather focus on the solution to the domain transfer problem.\n",
    "Settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=20 # max number of epochs\n",
    "lr=0.001 # learning rate\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a resnet18 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(label_map_all)\n",
    "model = resnet18(pretrained=True) # remove this if the model was already instansiated in the cell above\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "model = nn.DataParallel(model) \n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path='model' #path where model with best f1_macro should be stored\n",
    "\n",
    "#running variables\n",
    "epoch=0\n",
    "update_frequency=5 # number of batches before viewed acc and loss get updated\n",
    "counter=0 #counts batches\n",
    "f1_macro_best=0 #minimum f1_macro_score of the validation set for the first model to be saved\n",
    "loss_running=0\n",
    "acc_running=0\n",
    "val_batches=0\n",
    "\n",
    "y_pred=torch.tensor([], dtype=int)\n",
    "y_true=torch.tensor([], dtype=int)\n",
    "y_pred=y_pred.to(device)\n",
    "y_true=y_true.to(device)\n",
    "\n",
    "\n",
    "#Training\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    #training\n",
    "    model.train()\n",
    "    \n",
    "    with tqdm(train_loader) as tepoch:   \n",
    "        for i, data in enumerate(tepoch):\n",
    "            tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "            counter+=1\n",
    "\n",
    "            x, y = data\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            logits = torch.softmax(out.detach(), dim=1)\n",
    "            predictions = logits.argmax(dim=1)\n",
    "            acc = accuracy_score(y.cpu(), predictions.cpu())\n",
    "            \n",
    "            if counter >= update_frequency:\n",
    "                tepoch.set_postfix(loss=loss.item(), accuracy=acc.item())\n",
    "                counter=0\n",
    "                \n",
    "    #validation       \n",
    "    model.eval()\n",
    "    with tqdm(valid_loader) as vepoch: \n",
    "        for i, data in enumerate(vepoch):\n",
    "            vepoch.set_description(f\"Validation {epoch+1}\")\n",
    "\n",
    "            x, y = data\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            \n",
    "            logits = torch.softmax(out.detach(), dim=1)\n",
    "            predictions = logits.argmax(dim=1)\n",
    "            y_pred=torch.cat((y_pred, predictions), 0)\n",
    "            y_true=torch.cat((y_true, y), 0)\n",
    "            \n",
    "            acc = accuracy_score(y_true.cpu(), y_pred.cpu())\n",
    "            \n",
    "            loss_running+=(loss.item()*len(y))\n",
    "            acc_running+=(acc.item()*len(y))\n",
    "            val_batches+=len(y)\n",
    "            loss_mean=loss_running/val_batches\n",
    "            acc_mean=acc_running/val_batches\n",
    "            \n",
    "            vepoch.set_postfix(loss=loss_mean, accuracy=acc_mean)\n",
    "            \n",
    "        f1_micro=f1_score(y_true.cpu(), y_pred.cpu(), average='micro')\n",
    "        f1_macro=f1_score(y_true.cpu(), y_pred.cpu(), average='macro')\n",
    "        print(f'f1_micro: {f1_micro}, f1_macro: {f1_macro}')  \n",
    "        if f1_macro > f1_macro_best:\n",
    "            f1_macro_best=f1_macro\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print('model saved')\n",
    "        \n",
    "        #reseting running variables\n",
    "        loss_running=0\n",
    "        acc_running=0\n",
    "        val_batches=0\n",
    "            \n",
    "        y_pred=torch.tensor([], dtype=int)\n",
    "        y_true=torch.tensor([], dtype=int)\n",
    "        y_pred=y_pred.to(device)\n",
    "        y_true=y_true.to(device)\n",
    "            \n",
    "        \n",
    "    \n",
    "print('Finished Training')\n",
    "\n",
    "#loading the model with the highest validation accuracy\n",
    "model.load_state_dict(torch.load('model'))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Now we want to predict on the test datasetsof Acevedo_20 and Matek_19 and visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_test=example_metadata.loc[test_index,:]\n",
    "ace_metadata_test=metadata_test.loc[metadata_test['dataset']=='Ace_20'].reset_index(drop = True)\n",
    "mat_metadata_test=metadata_test.loc[metadata_test['dataset']=='Mat_19'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(metadata=metadata_test, \n",
    "               source_domains=['Ace_20', 'Mat_19'], label_map=label_map_all):\n",
    "\n",
    "\n",
    "\n",
    "    pred_dataset = DatasetGenerator(metadata, \n",
    "                                 reshape_size=resize, \n",
    "                                 dataset = source_domains,\n",
    "                                 label_map=label_map, \n",
    "                                 transform = test_transform,\n",
    "                                 )\n",
    "    \n",
    "    pred_loader = DataLoader(pred_dataset, \n",
    "                             batch_size=1, \n",
    "                             shuffle=False, \n",
    "                             num_workers=6\n",
    "                            )\n",
    "    n=len(pred_loader)\n",
    "    model.eval()\n",
    "    preds=torch.tensor([], dtype=int)\n",
    "    preds=preds.to(device)\n",
    "    prediction=torch.tensor([])\n",
    "    prediction=prediction.to(device)\n",
    "    for i, data in enumerate(pred_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        x, y = data\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model(x)\n",
    "        logits = torch.softmax(out.detach(), dim=1)\n",
    "        prediction = torch.cat((prediction, logits), 0)\n",
    "        predic = logits.argmax(dim=1)\n",
    "        preds=torch.cat((preds, predic), 0)\n",
    "\n",
    "    preds=preds.cpu()\n",
    "    preds=preds.detach().numpy()\n",
    "    np.save('preds', preds)\n",
    "    y_pred = [label_map_reverse[p] for p in  preds]\n",
    "    y_true=metadata['label']\n",
    "    return y_true, y_pred, preds\n",
    "\n",
    "def classification_complete_report(y_true, y_pred ,labels = None  ): \n",
    "    print(classification_report(y_true, y_pred, labels = None))\n",
    "    print(15*\"----\")\n",
    "    print(\"matthews correlation coeff: %.4f\" % (matthews_corrcoef(y_true, y_pred)) )\n",
    "    print(\"Cohen Kappa score: %.4f\" % (cohen_kappa_score(y_true, y_pred)) )\n",
    "    print(\"Accuracy: %.4f & balanced Accuracy: %.4f\" % (accuracy_score(y_true, y_pred), balanced_accuracy_score(y_true, y_pred)) )\n",
    "    #print(\"macro F1 score: %.4f & micro F1 score: %.4f\" % (f1_score(y_true, y_pred, average = \"macro\"), f1_score(y_true, y_pred, average = \"micro\")) )\n",
    "    print(\"macro Precision score: %.4f & micro Precision score: %.4f\" % (precision_score(y_true, y_pred, average = \"macro\"), precision_score(y_true, y_pred, average = \"micro\")) )\n",
    "    print(\"macro Recall score: %.4f & micro Recall score: %.4f\" % (recall_score(y_true, y_pred, average = \"macro\"), recall_score(y_true, y_pred, average = \"micro\")) )\n",
    "    print(labels)\n",
    "    cm = confusion_matrix(y_true, y_pred,labels= labels, normalize='true')\n",
    "    fig, ax = plt.subplots(figsize=(10, 10)) #plot size\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical', ax=ax, include_values=False, colorbar=False)\n",
    "    \n",
    "    plt.show()\n",
    "    print(15*\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acevedo_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred, preds=prediction(metadata= ace_metadata_test, source_domains=['Ace_20'])\n",
    "classification_complete_report(y_true, y_pred, labels=label_list_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matek_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred, preds=prediction(metadata= mat_metadata_test, source_domains=['Mat_19'])\n",
    "classification_complete_report(y_true, y_pred, labels=label_list_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred, preds=prediction(metadata=wbc_metadata, source_domains=['WBC1'], label_map=label_map_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a submission file for the prediction on WBC1 will be computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdata=wbc_metadata.drop(columns=['file', 'label', 'dataset', 'set', 'mean1', 'mean2', 'mean3'])\n",
    "outputdata['Label']=y_pred\n",
    "outputdata['LabelID']=preds\n",
    "'''\n",
    "for i in range(len(y_pred)):\n",
    "    outputdata['LabelID'].loc[i]=y_pred[i]\n",
    "    outputdata['Label'].loc[i]=label_map_reverse[y_pred[i]]\n",
    "'''\n",
    "outputdata.to_csv('submission.csv')\n",
    "print(outputdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKcxwPiyM42x"
   },
   "source": [
    "Now, you can open the submision.csv file (File -> Open) file and download it!\n",
    "\n",
    "After you download it, you can upload it to the frontend, here: XXX (direct link to the challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Authors\n",
    "\n",
    "Armin Gruber\n",
    "\n",
    "Ali Boushehri\n",
    "\n",
    "Christina Bukas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (ai_env)",
   "language": "python",
   "name": "ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
